
-- - -- notes franck -- -- -- 

range or hash

index in same or different tablet : how to measure impact ? 
index: overload? add extra fields to favour index-only lookup ? 

index: the first field is sharded by defulkt and next fieds are ordered.

scan is seek-next, seek-next.. and LSM tree. need to read up on LSM


IP or hostname: 
 - why does YB use IP, notably in the masterlist I cant get rid of IPs


PG-version: 
 - time to upgrade.. why the wait, what are the bottlenecks.


- -- -- 

-- how to prepare a yb-node (automate...):
 - bash-export $MASTERS and some aliases.
 - check yb-admin  
 - 

# useful cuts:

# cut out data from yb-admin, find tablet servers:
tsrvrs  | tail -n3 | cut -c1-38,39-49,66-70 
tsrvrs             | cut -c1-33,35-48,65-70,91-99
ybmast | cut -c1-33,35-48,65-70

# listing all tables with yb-admin: db, namespace, table-type (skip catalog), replace the dots by spaces
yb-admin -master_addresses $MASTERS list_tables  include_db_type include_table_id include_table_type | sed s'/\./\ /g' 

# list all tservers that serve a tablet, needs tablet-id
yb-admin -master_addresses $MASTERS  list_tablet_servers 04b26afaf0604684aabba96f3d35f419 


# get more info, dsar + yb_stats : get executable from githubmm

./dsar -H localhost -P 9001,9002,9003,9004,9005,9006 -o yb-cpu -i 1 
./dsar -H localhost -P 9001,9002,9003,9004,9005,9006 -o yb-io -i 4 
     
and to investigate entities... 
 ./yb_stats -H localhost -P 7001,7002 --print-entities | more 

./yb_stats -H localhost -P 7001,7002  --print-masters  

for failover, try  using an URI
ysqlsh postgresql://yugabyte@localhost:5434,localhost:5433,localhost:5432,localhost:5431 


worker node: nodeX 
- runs stand alone 1 db
- basrhc: same aliaes, but notably connecting to the cluster, via other nodes.
- failover in ysql-uri
- script to insert/sec.. : do_fill.sql
  add connected-host to filler
todo:
 - ensure pg-startup by removing sockets..
  rm -rf /tmp/.yb.*


scale-up to handle peak-usage..
 - Looking to scale up (not quite out) without extra nodes or shards
 - Can other nodes Read from shared or borrowed storage ? (e.g. read data without having to replicate data to read-only nodes)
 - 

next:
 - run container with bash, as vritual server.
 - test join/stop/start of nodes, from sever-level.
 - use hostnames ?
 - test procstat

Create own image with tools:
 - run node2 with all tools installed, but no yb started yet.
 - create an image from it:  
    $ docker commit node2 yb_plus_tools 
 - use the new image, using various mappings
    $ docker run -d --network yb_net --hostname node9 --name node9 \
            -p5439:5433 -p7009:7000 -p9009:9000 -p13439:13433 -p15439:15433 \
            yb_plus_tools \
            bash -xc 'do_stuff.sh ; tail -f /dev/null' 
 - notice: there is no yb-start command in there yet: could to include that in do_stuff.sh, only $hname is node-specific.


-- -- -- docker-compose.yaml for grafana dashboard -- -- --- -- -- 
name: ${COMPOSE_PROJECT_NAME}


services:

  grafana:
    image: grafana/grafana-oss:latest
    container_name: graph1
    hostname: graph1
    networks:
      - yb_net
    ports:
      - '3000:3000'
    extra_hosts:
      # the default connection is set to yb:5433 so rederecting it to `ip_of_yugabytedb_database` defined in `.env` which default to `host-gateway`
      - yb:172.20.0.3
    user: "0:0"
    privileged: true
    volumes:
      - .:/etc/grafanax:ro
      - .:/var/lib/grafana
    restart: unless-stopped

networks:
  yb_net:
    external: true
    name: yb_net

-- -- -- end of compose.yaml -- -- - -

